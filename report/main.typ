#import "Templates/style.typ": *

#set list(indent: 3em)

#show raw: set text(size: 12pt * 80%)
#show raw: set par(leading: 0.4em) 

#show figure: set block(breakable: true)
#show figure.where(kind: raw): set align(start)
#show figure.where(kind: raw): set block(inset: (left: 1em))

#show: itmoPracticeReport.with(
  organization: (
    full: "Национальный Исследовательский Университет ИТМО",
    short:"Университет ИТМО",
    logo: "logo_basic_russian_black.svg"
  ),
  city: "Санкт-Петербург",
  year: datetime.today().year(),

  title: "Разработка системы для сборки датасета для диффузионной модели управления манипулятором",
  abstract: include "abstract.typ",
  keywords: ("манипулятор", "датасет", "телеоператор",
    "UR5e"),

  author: (
    name: "Смирнов Алексей Владимирович",
    isu: "409578",
  ),
  supervisor: (
    name: "Ведяков Алексей Алексеевич",
    regalia: "Кандидат технических наук; доцент",
  ),
)

#introduction[
Практика проходила в лаборатории при университете ИТМО в период с
17 по 30 июня. 

Цель практики --- исследование

Для достижения цели были сформулированы следующие задачи на практику:
  - Инструктаж обущающегося
  - Ознакомление со статьёй
  - Настройка окружения
  - Разработка системы телеоператора для манипулятора
  - Разработка системы сохранения телеметрии

для сборки датасета с промышленного манипулятора UR5e, предназначенного
для последующего обучения диффузионной модели.
]

= Обзор источников

Рассмотрели статью Chi C. --- Diffusion Policy @chi2024diffusionpolicy .
В ней авторы предлагают использовать диффузионную модель для предсказания
точек траектории движения манипулятора.

Изначальной целью проекта было повторить результат авторов, но ввиду
ограниченного времени решили сузить цель до: Создать установку для сбора
датасета для одного сценария.

В статье рассмотрены разные сценарии: толкание фигурки в указанное место,
распределение соуса по пицце и другие. Остановились на сценарии с фигуркой.

Провели анализ датасета авторов: они использовали следующие данные:

- видео с 4-х ракурсов
- текущие скорости и положения суставов манипулятора
- текущие скорости и положение энд-эффектрора манипулятора
- целевое положение энд-эффектора манипулятора
- этап сценария внутри эксперимента


= Настройка окружения

Первой задачей была настройка рабочека окружения, включая симулятор Universal
Robots UR Sim, библиотеку `ur-rtde` для языка Python.

== Установка библиотеки RTDE

На этом этапе столкнулись с проблемой ошибки сборки пакета. Используемый пакет
`ur-rtde` написан на языке C++ и включает интерфейсы для языка python. Решили
проблему сменив главную версию системы сборки CMake с 4 на 3.

== Настройка симулятора UR Sim

Производитель манипулятора Universal Robots предлагает использовать
симулятор UR5e и распространяет его в виде Docker-образа.
Настроили окружение для запуска симулятора при помощи инструмента
docker-compose (@docker) :

= Разработка системы телеоператора для манипулятра

Так как используем метод обучения с учителем, необходимо создать датасет,
в котором манипулятор выполняет задачу под управлением человека.

Для этого было два возможных варианта: кинестатика и телеоператор.
Первый вариант значительно проще в реализации: человек руками двигает робота,
но у него есть значительных недостаток: на видео всегда будет человек, 
из-за чего модель может обучиться хуже.

Поэтому выбрали второй способ: телеоператор с джойстика. Для реализации этого
метода написали модуль программы, который считывает данных с джойстика в
реальном времени с большой частотой (@controller). 

Проанализировали, какой функционал необходимо вынести на джойстик. В конечном
варианте у телеоператора есть следующие возможности:

- Перемещение энд-эффектора по плоскости XY 
- изменение скорости движения
- обозначение текущего этапа сценария
- начало и остановка записи сценария

== Реализация управления манипулятором

Отклонения стика (нормализованное, с примененными метрвыми зонами) умножается
на множитель скорости и задается как скорость энд-эффектора в плоскости XY:

```py
103  left_stick = self.controller.leftStickPos()
104  sp = np.zeros(6)
105  sp[0] = -left_stick[0] * self.velocityMultiplier
106  sp[1] = -left_stick[1] * self.velocityMultiplier
107
108  self.rtde_c.speedL(sp, 1.0)
```

= Сбор телеметрии

== Данные с сенсоров

Использовали тот же формат, что и авторы статьи: zarr.
Для сохранения телеметрии написали отдельный модуль (@logger).

== Видео

Для записи видео использовали несколько IP-камер. Считывали кадры
при помощи библиотеки OpenCV. На этом этапе самым сложным было ---
синхронизация видео по времени (начало и сохранeние записей с 
нескольких камер) одновременно.

Для решения этой проблемы использовали механизм многопоточности:
за каждую камеру отвечает отдельный процесс (См. @camera).


#conclusion[

Выполнив все поставленные задачи и объединив все модули в одну программу
получили систему для сбора датасета для диффузионной модели из рассмотренной
статьи.

== Основной модуль

Основной модуль программы (@teleop) объединяет все ранее упомянутые модули.
Итерация основного цикла работы программы выглядит следующим образом:

```py
    def loop(self, target_time=.05):

        while True:
            dt = time.time()

            self.handleBtns()
            self.handleTelemetry()

            self.statusLine()

            left_stick = self.controller.leftStickPos()
            sp = np.zeros(6)
            sp[0] = -left_stick[0] * self.velocityMultiplier
            sp[1] = -left_stick[1] * self.velocityMultiplier

            self.rtde_c.speedL(sp, 1.0)

            dt = time.time() - dt
            if dt > target_time:
                print("WARN cycle time too high")
            else:
                sleep_time = max(0, target_time - dt)
                time.sleep(sleep_time)
            self.epTick += 1
```
]

= Результаты

В результате проекта получили рабочую установку для записи датасета
на манипуляторе UR5e для сценария с толканием фигурки на плоскости.
Исходный код проекта можно найти в онлайн-репозитории (См. Приложение).

Помимо этого, записали демонстрацию работы установки на видео (См. Приложение).
В репозитории также можно найти записи с камер и телеметрию, записанные во время демонстрации.

#annex[

Демонстрация работы системы (видео): \ 
  #link("https://drive.google.com/file/d/1LrgIu6aEk7I5UbFf9WPFpyLqs9BmqrW-/view?usp=share_link")


Исходный код проекта: \ 
  #link("https://github.com/Hanqnero/DiffusionPolicy-dataset-setup")


#figure(
  raw(read("../docker-compose.yml"), lang: "yaml"),
  caption: [docker-compose.yml для образа симулятора]
) <docker>

#figure(
  raw(read("../src/controller.py"), lang: "py"),
  caption: [Модуль для чтения данных с джойстика]
) <controller>

#figure(
  raw(read("../src/zarr_logger.py"), lang: "py"),
  caption: [Модуль для сохраниния телеметрии с сенсоров робота]
) <logger>

#figure(
  raw(read("../src/camera.py"), lang: "py"),
  caption: [Модуль для сохраниния видео с камер]
) <camera>

#figure(
  raw(read("../src/teleop.py"), lang: "py"),
  caption: [Основной модуль программы]
) <teleop>

#bibliography(
  "refs.bib",
  full: true,
  style: "gost-r-705-2008-numeric"
)
]



// vim:set noai et ts=2 sw=2 tw=70
